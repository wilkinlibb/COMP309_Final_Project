# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hZyJ3nJlESCbq4kygquJjQ5Hwalo671G
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torch.nn.functional as F

from torch.utils.data import DataLoader, random_split, Subset

from torchvision import models

from sklearn.metrics import precision_score, recall_score, f1_score
from PIL import Image
import os

# Define the CNN class (same as in train.py)
class CNN(nn.Module):
    def __init__(self, num_classes=3):
        super(CNN, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        for param in self.resnet.parameters():
            param.requires_grad = False
        self.resnet.fc = nn.Identity()

        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)

        self.fc1 = nn.Linear(16 * 53 * 53 + 512, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, num_classes)

    def forward(self, x):
        resnet_features = self.resnet(x)
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)
        combined_features = torch.cat((resnet_features, x), dim=1)

        x = F.relu(self.fc1(combined_features))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# load the saved model
device = "cuda" if torch.cuda.is_available() else "cpu"
model = CNN(num_classes=3).to(device)
model.load_state_dict(torch.load('model.pth', map_location=device))
model.eval()

# image pre-processing transformation (same as in train.py)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# define a mapping of labels based on file names
class_map = {
    "cherry": 0,
    "strawberry": 1,
    "tomato": 2
}

# test image directory
test_data_dir = 'testdata'
correct = 0
total = 0

# variables to capture metrics
total_loss = 0.0
all_preds = []
all_labels = []

# inference on each image
with torch.no_grad():
    for filename in os.listdir(test_data_dir):
        if filename.endswith(".jpg") or filename.endswith(".png"):  # check for image files

            # open image and apply transformations
            img_path = os.path.join(test_data_dir, filename)
            image = Image.open(img_path).convert('RGB')
            image = transform(image).unsqueeze(0).to(device)

            # perform inference
            output = model(image)
            _, predicted = torch.max(output, 1)
            predicted = predicted.item()

            # get actual class from filename
            true_label = class_map.get(next((keyword for keyword in class_map if keyword in filename), None), None)
            if true_label is not None:
                loss = F.cross_entropy(output, torch.tensor([true_label]).to(device))  # calculate loss
                total_loss += loss.item()                                              # accumulate total loss

                # update counts for accuracy
                total += 1
                correct += (predicted == true_label)

                # collect predictions and true labels for metrics
                all_preds.append(predicted)
                all_labels.append(true_label)

# accuracy
accuracy = 100 * correct / total if total > 0 else 0
print(f'Overall Accuracy: {accuracy:.2f}%')

# average loss
average_loss = total_loss / total if total > 0 else 0
print(f'Average Loss: {average_loss:.4f}')

# precision, recall, f1
precision = precision_score(all_labels, all_preds, average='weighted') if all_labels else 0
recall = recall_score(all_labels, all_preds, average='weighted') if all_labels else 0
f1 = f1_score(all_labels, all_preds, average='weighted') if all_labels else 0

print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# save results to a text file
with open("test_results.txt", "w") as f:
    f.write(f"Overall Accuracy: {accuracy:.2f}%\n")
    f.write(f"Average Loss: {average_loss:.4f}\n")
    f.write(f"Precision: {precision:.4f}\n")
    f.write(f"Recall: {recall:.4f}\n")
    f.write(f"F1 Score: {f1:.4f}\n")